{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb11f07b-a2d7-4861-856f-ddd053f93c66",
   "metadata": {},
   "source": [
    "### CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "a4d71233-7ba1-44cb-9063-359d649b5848",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, regularizers\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import KFold\n",
    "from src.dataLoading import dataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "import itertools\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "46d537f9-0f30-453d-b6fc-f3f19fa611cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU Available:  True\n"
     ]
    }
   ],
   "source": [
    "print(\"GPU Available: \", tf.test.is_gpu_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13d23119-5a4c-4c9f-a636-e2e6e5c02ea2",
   "metadata": {},
   "source": [
    "#### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "0b91458d-123d-49a8-93dd-6356b18efaf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors, images, labels = dataLoader(mnist_only=False, chinese_mnist_only=False)  # 784-long vectors, 28*28 images and mnist/chinese labels\n",
    "\n",
    "encoder = LabelBinarizer()\n",
    "transfomed_labels = encoder.fit(np.unique(labels))\n",
    "# split the vectors (for PCA, CNN would use images)\n",
    "# \"stratify\" makes sure theres a balance of each class in the test/train sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(vectors, labels, train_size=0.8, stratify=labels)\n",
    "y_train_t = encoder.transform(y_train)\n",
    "y_test_t = encoder.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b3bdf594-68f8-4112-be82-b0e2f79206ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.reshape(X_train, (X_train.shape[0],28,28,1))\n",
    "X_test = np.reshape(X_test, (X_test.shape[0],28,28,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "3f61d8d0-6068-4122-8306-4736a1a70970",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE=64\n",
    "STEPS_PER_EPOCH = X_train.shape[0]//BATCH_SIZE\n",
    "\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\n",
    "]\n",
    "lr_schedule = tf.keras.optimizers.schedules.InverseTimeDecay(\n",
    "  0.001,\n",
    "  decay_steps=STEPS_PER_EPOCH*1000,\n",
    "  decay_rate=1,\n",
    "  staircase=False)\n",
    "\n",
    "\n",
    "def create_model(input_shape, output_shape):\n",
    "    model = tf.keras.models.Sequential()\n",
    "    model.add(layers.Conv2D(32, (3, 3), activation=None, input_shape=input_shape))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.Activation('relu'))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    model.add(layers.Conv2D(64, (3, 3), activation=None))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.Activation('relu'))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    model.add(layers.Conv2D(128, (3, 3), activation=None))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.Activation('relu'))\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dropout(0.3)),\n",
    "    model.add(layers.Dense(64, kernel_regularizer=regularizers.L1L2(l1=0.00, l2=0.00), activation='relu'))\n",
    "    model.add(layers.Dropout(0.3)),\n",
    "    model.add(layers.Dense(32, kernel_regularizer=regularizers.L1L2(l1=0.00, l2=0.00), activation='relu'))\n",
    "    model.add(layers.Dropout(0.3)),\n",
    "    model.add(layers.Dense(output_shape))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "2d667f69-1e30-44c7-b3f8-3062cb4fc5d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_35\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_74 (Conv2D)           (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "batch_normalization_54 (Batc (None, 26, 26, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_74 (Activation)   (None, 26, 26, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_70 (MaxPooling (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_75 (Conv2D)           (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_55 (Batc (None, 11, 11, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_75 (Activation)   (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_71 (MaxPooling (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_76 (Conv2D)           (None, 3, 3, 128)         73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_56 (Batc (None, 3, 3, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_76 (Activation)   (None, 3, 3, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_35 (Flatten)         (None, 1152)              0         \n",
      "_________________________________________________________________\n",
      "dropout_74 (Dropout)         (None, 1152)              0         \n",
      "_________________________________________________________________\n",
      "dense_74 (Dense)             (None, 64)                73792     \n",
      "_________________________________________________________________\n",
      "dropout_75 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_75 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dropout_76 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_76 (Dense)             (None, 20)                660       \n",
      "=================================================================\n",
      "Total params: 170,100\n",
      "Trainable params: 169,652\n",
      "Non-trainable params: 448\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = create_model(X_train.shape[1:], y_train_t.shape[-1])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "ce52ec10-6203-4248-85fc-0cabc1ae7b4b",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "225/225 [==============================] - 37s 126ms/step - loss: 1.2915 - accuracy: 0.6040 - val_loss: 0.2836 - val_accuracy: 0.9325\n",
      "Epoch 2/50\n",
      "225/225 [==============================] - 28s 123ms/step - loss: 0.4368 - accuracy: 0.8697 - val_loss: 0.1073 - val_accuracy: 0.9712\n",
      "Epoch 3/50\n",
      "225/225 [==============================] - 18s 80ms/step - loss: 0.2938 - accuracy: 0.9135 - val_loss: 0.0729 - val_accuracy: 0.9806\n",
      "Epoch 4/50\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.2199 - accuracy: 0.9371 - val_loss: 0.0625 - val_accuracy: 0.9819\n",
      "Epoch 5/50\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.1852 - accuracy: 0.9450 - val_loss: 0.0850 - val_accuracy: 0.9831\n",
      "Epoch 6/50\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.1589 - accuracy: 0.9544 - val_loss: 0.0762 - val_accuracy: 0.9800\n",
      "Epoch 7/50\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.1363 - accuracy: 0.9605 - val_loss: 0.0557 - val_accuracy: 0.9881\n",
      "Epoch 8/50\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.1234 - accuracy: 0.9653 - val_loss: 0.0377 - val_accuracy: 0.9931\n",
      "Epoch 9/50\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.1092 - accuracy: 0.9678 - val_loss: 0.0574 - val_accuracy: 0.9856\n",
      "Epoch 10/50\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.0956 - accuracy: 0.9717 - val_loss: 0.0598 - val_accuracy: 0.9887\n",
      "Epoch 11/50\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.1026 - accuracy: 0.9703 - val_loss: 0.0669 - val_accuracy: 0.9837\n",
      "Epoch 12/50\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.0971 - accuracy: 0.9720 - val_loss: 0.0466 - val_accuracy: 0.9900\n",
      "Epoch 13/50\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.0832 - accuracy: 0.9765 - val_loss: 0.0493 - val_accuracy: 0.9900\n",
      "Epoch 14/50\n",
      "225/225 [==============================] - 2s 10ms/step - loss: 0.0738 - accuracy: 0.9783 - val_loss: 0.0418 - val_accuracy: 0.9894\n",
      "Epoch 15/50\n",
      "225/225 [==============================] - 2s 11ms/step - loss: 0.0709 - accuracy: 0.9787 - val_loss: 0.0640 - val_accuracy: 0.9862\n",
      "Epoch 16/50\n",
      "225/225 [==============================] - 2s 10ms/step - loss: 0.0668 - accuracy: 0.9810 - val_loss: 0.0645 - val_accuracy: 0.9869\n",
      "Epoch 17/50\n",
      "225/225 [==============================] - 2s 10ms/step - loss: 0.0592 - accuracy: 0.9834 - val_loss: 0.0336 - val_accuracy: 0.9925\n",
      "Epoch 18/50\n",
      "225/225 [==============================] - 2s 10ms/step - loss: 0.0709 - accuracy: 0.9797 - val_loss: 0.0405 - val_accuracy: 0.9887\n",
      "Epoch 19/50\n",
      "225/225 [==============================] - 2s 10ms/step - loss: 0.0627 - accuracy: 0.9806 - val_loss: 0.0418 - val_accuracy: 0.9869\n",
      "Epoch 20/50\n",
      "225/225 [==============================] - 2s 9ms/step - loss: 0.0559 - accuracy: 0.9831 - val_loss: 0.0497 - val_accuracy: 0.9887\n",
      "Epoch 21/50\n",
      "225/225 [==============================] - 2s 10ms/step - loss: 0.0510 - accuracy: 0.9837 - val_loss: 0.0468 - val_accuracy: 0.9894\n",
      "Epoch 22/50\n",
      "225/225 [==============================] - 2s 10ms/step - loss: 0.0533 - accuracy: 0.9841 - val_loss: 0.0460 - val_accuracy: 0.9894\n",
      "Epoch 23/50\n",
      "225/225 [==============================] - 2s 10ms/step - loss: 0.0446 - accuracy: 0.9865 - val_loss: 0.0558 - val_accuracy: 0.9875\n",
      "Epoch 24/50\n",
      "225/225 [==============================] - 2s 10ms/step - loss: 0.0587 - accuracy: 0.9838 - val_loss: 0.0446 - val_accuracy: 0.9887\n",
      "Epoch 25/50\n",
      "225/225 [==============================] - 2s 10ms/step - loss: 0.0501 - accuracy: 0.9855 - val_loss: 0.0495 - val_accuracy: 0.9881\n",
      "Epoch 26/50\n",
      "225/225 [==============================] - 2s 10ms/step - loss: 0.0465 - accuracy: 0.9873 - val_loss: 0.0762 - val_accuracy: 0.9862\n",
      "Epoch 27/50\n",
      "225/225 [==============================] - 2s 10ms/step - loss: 0.0474 - accuracy: 0.9864 - val_loss: 0.0595 - val_accuracy: 0.9894\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(lr_schedule),\n",
    "              loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X_train, y_train_t, epochs=50, batch_size=64,\n",
    "                    validation_split=0.1, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4d8e846-b2ca-4168-b8b4-5bbf52a432e8",
   "metadata": {},
   "source": [
    "### Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b0d89dc6-2b2a-42f7-92a9-71a254763136",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total number of combinations: 160\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 100\n",
    "BATCH_SIZE = [32, 64]\n",
    "l1 = [0.1, 0.01, 0.001]\n",
    "l2 = [0.1, 0.01, 0.001]\n",
    "dropouts = [0.5, 0.2]\n",
    "conv_models = [\n",
    "    [32, 64],\n",
    "    [32, 64, 128],\n",
    "    [16, 32],\n",
    "    [16, 32, 64],\n",
    "    [64, 128],\n",
    "    # [64, 128, 256]\n",
    "]\n",
    "add_batch_norm = [True, False]\n",
    "dense_models = [\n",
    "    [32],\n",
    "    # [128, 64],\n",
    "    [64],\n",
    "    [64, 32],\n",
    "    # [128, 32],\n",
    "    [128]\n",
    "]\n",
    "parameters = list(itertools.product(*[conv_models, add_batch_norm, dense_models, dropouts, BATCH_SIZE]))\n",
    "print(f'total number of combinations: {len(parameters)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "831e3f2c-d9b0-463d-b34a-32dfa3d1bad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_2(input_shape, output_shape, conv_layers, batch_norm, dense_layers, dropout, steps_per_epoch):\n",
    "    model = tf.keras.models.Sequential()\n",
    "    for idx, val in enumerate(conv_layers):\n",
    "        if(idx == 0):\n",
    "            model.add(layers.Conv2D(val, (3, 3), activation=None, input_shape=input_shape))\n",
    "        else:\n",
    "            model.add(layers.Conv2D(val, (3, 3), activation=None))\n",
    "        if(batch_norm):\n",
    "            model.add(layers.BatchNormalization())\n",
    "        model.add(layers.Activation('relu'))\n",
    "        model.add(layers.MaxPooling2D((2, 2)))\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dropout(dropout)),\n",
    "    for idx, val in enumerate(dense_layers):\n",
    "        model.add(layers.Dense(val, kernel_regularizer=regularizers.L1L2(l1=0.00, l2=0.00), activation='relu'))\n",
    "        model.add(layers.Dropout(dropout)),\n",
    "    model.add(layers.Dense(output_shape))\n",
    "       \n",
    "    lr_schedule = tf.keras.optimizers.schedules.InverseTimeDecay(\n",
    "      0.001,\n",
    "      decay_steps=steps_per_epoch*1000,\n",
    "      decay_rate=1,\n",
    "      staircase=False)\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(lr_schedule),\n",
    "        loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "        metrics=['accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48fb3275-cc19-4833-b80c-ba9d681a1695",
   "metadata": {},
   "source": [
    "### Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "75c8f707-ee8d-48ad-a08e-fd2e2ea26720",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "def cross_validate(conv_model, batch_norm, dense_model, dropout, batch_size, k_folds=10):\n",
    "    acc_per_fold = []\n",
    "    loss_per_fold = []\n",
    "    num_folds = 10\n",
    "    kfold = KFold(n_splits=num_folds, shuffle=True)\n",
    "    fold_n = 1\n",
    "    for train, test in kfold.split(X_train, y_train_t):\n",
    "        print(f'FOLD {fold_n}')\n",
    "        model = create_model_2(X_train.shape[1:], y_train_t.shape[-1], conv_model, batch_norm, dense_model, dropout,  X_train.shape[0]//batch_size)\n",
    "        callbacks = [\n",
    "            tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\n",
    "        ]\n",
    "        history = model.fit(\n",
    "            X_train[train],\n",
    "            y_train_t[train],\n",
    "            epochs=EPOCHS,\n",
    "            batch_size=batch_size,\n",
    "            validation_split=0.1,\n",
    "            verbose=2,\n",
    "            callbacks=callbacks\n",
    "        )\n",
    "        test_loss, test_acc = model.evaluate(X_train[test], y_train_t[test], verbose=2)\n",
    "        print(f'Score for fold {fold_n}: {model.metrics_names[0]} of {test_loss}; {model.metrics_names[1]} of {test_acc*100}%')\n",
    "        acc_per_fold.append(test_acc * 100)\n",
    "        loss_per_fold.append(test_loss)\n",
    "        fold_n += 1\n",
    "    return [np.mean(acc_per_fold), np.mean(loss_per_fold)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8217497c-5eae-45d1-be22-3c6660f11d0e",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 1\n",
      "Epoch 1/100\n",
      "405/405 - 3s - loss: 2.4601 - accuracy: 0.2239 - val_loss: 1.1302 - val_accuracy: 0.7556\n",
      "Epoch 2/100\n",
      "405/405 - 2s - loss: 1.5570 - accuracy: 0.4818 - val_loss: 0.4666 - val_accuracy: 0.9146\n",
      "Epoch 3/100\n",
      "405/405 - 2s - loss: 1.2115 - accuracy: 0.5806 - val_loss: 0.3699 - val_accuracy: 0.9201\n",
      "Epoch 4/100\n",
      "405/405 - 2s - loss: 1.0208 - accuracy: 0.6426 - val_loss: 0.2466 - val_accuracy: 0.9486\n",
      "Epoch 5/100\n",
      "405/405 - 2s - loss: 0.9010 - accuracy: 0.6846 - val_loss: 0.1865 - val_accuracy: 0.9597\n",
      "Epoch 6/100\n",
      "405/405 - 2s - loss: 0.8294 - accuracy: 0.7066 - val_loss: 0.1674 - val_accuracy: 0.9590\n",
      "Epoch 7/100\n",
      "405/405 - 2s - loss: 0.7627 - accuracy: 0.7294 - val_loss: 0.1409 - val_accuracy: 0.9646\n",
      "Epoch 8/100\n",
      "405/405 - 2s - loss: 0.6761 - accuracy: 0.7609 - val_loss: 0.1419 - val_accuracy: 0.9639\n",
      "Epoch 9/100\n",
      "405/405 - 2s - loss: 0.6355 - accuracy: 0.7785 - val_loss: 0.1156 - val_accuracy: 0.9694\n",
      "Epoch 10/100\n",
      "405/405 - 2s - loss: 0.5417 - accuracy: 0.8142 - val_loss: 0.1085 - val_accuracy: 0.9708\n",
      "Epoch 11/100\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m-----------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [55], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m means \u001b[38;5;241m=\u001b[39m [cross_validate(conv_model, batch_norm, dense_model, dropout, batch_size) \u001b[38;5;28;01mfor\u001b[39;00m conv_model, batch_norm, dense_model, dropout, batch_size \u001b[38;5;129;01min\u001b[39;00m parameters[:\u001b[38;5;241m1\u001b[39m]]\n",
      "Cell \u001b[1;32mIn [55], line 1\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[1;32m----> 1\u001b[0m means \u001b[38;5;241m=\u001b[39m [\u001b[43mcross_validate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconv_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_norm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdense_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m conv_model, batch_norm, dense_model, dropout, batch_size \u001b[38;5;129;01min\u001b[39;00m parameters[:\u001b[38;5;241m1\u001b[39m]]\n",
      "Cell \u001b[1;32mIn [53], line 13\u001b[0m, in \u001b[0;36mcross_validate\u001b[1;34m(conv_model, batch_norm, dense_model, dropout, batch_size, k_folds)\u001b[0m\n\u001b[0;32m      9\u001b[0m model \u001b[38;5;241m=\u001b[39m create_model_2(X_train\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m:], y_train_t\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], conv_model, batch_norm, dense_model, dropout,  X_train\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39mbatch_size)\n\u001b[0;32m     10\u001b[0m callbacks \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     11\u001b[0m     tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mcallbacks\u001b[38;5;241m.\u001b[39mEarlyStopping(monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)\n\u001b[0;32m     12\u001b[0m ]\n\u001b[1;32m---> 13\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_train_t\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mEPOCHS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\n\u001b[0;32m     21\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     22\u001b[0m test_loss, test_acc \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mevaluate(X_train[test], y_train_t[test], verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mScore for fold \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfold_n\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel\u001b[38;5;241m.\u001b[39mmetrics_names[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_loss\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m; \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel\u001b[38;5;241m.\u001b[39mmetrics_names[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_acc\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m100\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\Miniconda3\\envs\\u\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1183\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1176\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m trace\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1177\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   1178\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   1179\u001b[0m     step_num\u001b[38;5;241m=\u001b[39mstep,\n\u001b[0;32m   1180\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[0;32m   1181\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m   1182\u001b[0m   callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1183\u001b[0m   tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1184\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1185\u001b[0m     context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\Miniconda3\\envs\\u\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:889\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    886\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    888\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 889\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    891\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    892\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\Miniconda3\\envs\\u\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:917\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    914\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    915\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    916\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 917\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateless_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    918\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    919\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    920\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    921\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32m~\\Miniconda3\\envs\\u\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3023\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3020\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m   3021\u001b[0m   (graph_function,\n\u001b[0;32m   3022\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 3023\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3024\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Miniconda3\\envs\\u\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1960\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1956\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1957\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1958\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1959\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1960\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1961\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1962\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1963\u001b[0m     args,\n\u001b[0;32m   1964\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1965\u001b[0m     executing_eagerly)\n\u001b[0;32m   1966\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\Miniconda3\\envs\\u\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:591\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    589\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    590\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 591\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    592\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    593\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    594\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    595\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    596\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    597\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    598\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    599\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m    600\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    603\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[0;32m    604\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32m~\\Miniconda3\\envs\\u\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:59\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     58\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 59\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     60\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     62\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "means = [cross_validate(conv_model, batch_norm, dense_model, dropout, batch_size) for conv_model, batch_norm, dense_model, dropout, batch_size in parameters[:1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "06b92f02-a686-45f5-8480-dc853fd941eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.88874996e+01, 4.46845509e-02],\n",
       "       [9.84562498e+01, 6.14750601e-02]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(means)[:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ef06d396-f5b5-4718-8f4a-89ec863b6a40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top model Configurations\n",
      "[([32, 64], True, [64], 0.5, 64), ([32, 64], False, [64], 0.5, 64)]\n"
     ]
    }
   ],
   "source": [
    "top_params = [parameters[idx] for idx in np.argsort(np.array(means)[:,0])[::-1][:3]]\n",
    "print('Top model Configurations')\n",
    "print(top_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b34a658a-e9b1-42de-a0d5-a296bad286f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top mean accuracies and losses\n",
      "[[98.88749957084656, 0.04468455091118813], [98.456249833107, 0.06147506013512612]]\n"
     ]
    }
   ],
   "source": [
    "top_means = [means[idx] for idx in np.argsort(np.array(means)[:,0])[::-1][:3]]\n",
    "print('Top mean accuracies and losses')\n",
    "print(top_means)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f6b8197-5fe1-42d1-882b-d074e58bc339",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "03059a99-9e5d-4636-b991-dab37511d218",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,sys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "33e5cb64-dba6-4393-9047-da3817a8b554",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'H:\\\\My Drive\\\\Master\\\\Machine_Learning\\\\MachineLearning-2022'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.abspath('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "312ae43a-6719-4350-a5b7-5498bccd0ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = os.path.sep.join([os.path.abspath(''), 'saved_models',\n",
    "\t\"weights-{epoch:03d}-{val_loss:.4f}.hdf5\"])\n",
    "final_callbacks = [\n",
    "    # tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10),\n",
    "    tf.keras.callbacks.ModelCheckpoint(\n",
    "        filepath=fname,\n",
    "        save_weights_only=False,\n",
    "        monitor='val_accuracy',\n",
    "        mode='max',\n",
    "        save_best_only=True,\n",
    "        verbose=1)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f995a1d5-0f61-41da-ae62-3a24f8de789f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b174af63-cbd3-43dd-a1a7-5428d88f8978",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "225/225 [==============================] - 9s 34ms/step - loss: 2.0770 - accuracy: 0.3590 - val_loss: 0.5531 - val_accuracy: 0.8850\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.88500, saving model to H:\\My Drive\\Master\\Machine_Learning\\MachineLearning-2022\\saved_models\\weights-001-0.5531.hdf5\n",
      "Epoch 2/100\n",
      "225/225 [==============================] - 6s 25ms/step - loss: 0.9079 - accuracy: 0.7078 - val_loss: 0.2072 - val_accuracy: 0.9469\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.88500 to 0.94687, saving model to H:\\My Drive\\Master\\Machine_Learning\\MachineLearning-2022\\saved_models\\weights-002-0.2072.hdf5\n",
      "Epoch 3/100\n",
      "225/225 [==============================] - 5s 24ms/step - loss: 0.5968 - accuracy: 0.8067 - val_loss: 0.1380 - val_accuracy: 0.9706\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.94687 to 0.97062, saving model to H:\\My Drive\\Master\\Machine_Learning\\MachineLearning-2022\\saved_models\\weights-003-0.1380.hdf5\n",
      "Epoch 4/100\n",
      "225/225 [==============================] - 6s 26ms/step - loss: 0.4868 - accuracy: 0.8444 - val_loss: 0.1194 - val_accuracy: 0.9681\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.97062\n",
      "Epoch 5/100\n",
      "225/225 [==============================] - 5s 22ms/step - loss: 0.4024 - accuracy: 0.8724 - val_loss: 0.1162 - val_accuracy: 0.9725\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.97062 to 0.97250, saving model to H:\\My Drive\\Master\\Machine_Learning\\MachineLearning-2022\\saved_models\\weights-005-0.1162.hdf5\n",
      "Epoch 6/100\n",
      "225/225 [==============================] - 5s 24ms/step - loss: 0.3576 - accuracy: 0.8842 - val_loss: 0.1044 - val_accuracy: 0.9706\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.97250\n",
      "Epoch 7/100\n",
      "225/225 [==============================] - 5s 23ms/step - loss: 0.3334 - accuracy: 0.8931 - val_loss: 0.0986 - val_accuracy: 0.9744\n",
      "\n",
      "Epoch 00007: val_accuracy improved from 0.97250 to 0.97438, saving model to H:\\My Drive\\Master\\Machine_Learning\\MachineLearning-2022\\saved_models\\weights-007-0.0986.hdf5\n",
      "Epoch 8/100\n",
      "225/225 [==============================] - 5s 22ms/step - loss: 0.2966 - accuracy: 0.9040 - val_loss: 0.0795 - val_accuracy: 0.9756\n",
      "\n",
      "Epoch 00008: val_accuracy improved from 0.97438 to 0.97562, saving model to H:\\My Drive\\Master\\Machine_Learning\\MachineLearning-2022\\saved_models\\weights-008-0.0795.hdf5\n",
      "Epoch 9/100\n",
      "225/225 [==============================] - 5s 22ms/step - loss: 0.2713 - accuracy: 0.9102 - val_loss: 0.0822 - val_accuracy: 0.9800\n",
      "\n",
      "Epoch 00009: val_accuracy improved from 0.97562 to 0.98000, saving model to H:\\My Drive\\Master\\Machine_Learning\\MachineLearning-2022\\saved_models\\weights-009-0.0822.hdf5\n",
      "Epoch 10/100\n",
      "225/225 [==============================] - 6s 25ms/step - loss: 0.2605 - accuracy: 0.9143 - val_loss: 0.0768 - val_accuracy: 0.9781\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.98000\n",
      "Epoch 11/100\n",
      "225/225 [==============================] - 5s 24ms/step - loss: 0.2332 - accuracy: 0.9225 - val_loss: 0.0805 - val_accuracy: 0.9794\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.98000\n",
      "Epoch 12/100\n",
      "225/225 [==============================] - 6s 25ms/step - loss: 0.2336 - accuracy: 0.9227 - val_loss: 0.0695 - val_accuracy: 0.9819\n",
      "\n",
      "Epoch 00012: val_accuracy improved from 0.98000 to 0.98188, saving model to H:\\My Drive\\Master\\Machine_Learning\\MachineLearning-2022\\saved_models\\weights-012-0.0695.hdf5\n",
      "Epoch 13/100\n",
      "225/225 [==============================] - 6s 28ms/step - loss: 0.2248 - accuracy: 0.9279 - val_loss: 0.0661 - val_accuracy: 0.9837\n",
      "\n",
      "Epoch 00013: val_accuracy improved from 0.98188 to 0.98375, saving model to H:\\My Drive\\Master\\Machine_Learning\\MachineLearning-2022\\saved_models\\weights-013-0.0661.hdf5\n",
      "Epoch 14/100\n",
      "225/225 [==============================] - 7s 29ms/step - loss: 0.2120 - accuracy: 0.9304 - val_loss: 0.0686 - val_accuracy: 0.9819\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.98375\n",
      "Epoch 15/100\n",
      "225/225 [==============================] - 5s 24ms/step - loss: 0.1877 - accuracy: 0.9395 - val_loss: 0.0563 - val_accuracy: 0.9850\n",
      "\n",
      "Epoch 00015: val_accuracy improved from 0.98375 to 0.98500, saving model to H:\\My Drive\\Master\\Machine_Learning\\MachineLearning-2022\\saved_models\\weights-015-0.0563.hdf5\n",
      "Epoch 16/100\n",
      "225/225 [==============================] - 5s 23ms/step - loss: 0.1803 - accuracy: 0.9428 - val_loss: 0.0649 - val_accuracy: 0.9825\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.98500\n",
      "Epoch 17/100\n",
      "225/225 [==============================] - 5s 21ms/step - loss: 0.1769 - accuracy: 0.9438 - val_loss: 0.0588 - val_accuracy: 0.9812\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.98500\n",
      "Epoch 18/100\n",
      "225/225 [==============================] - 5s 24ms/step - loss: 0.1742 - accuracy: 0.9447 - val_loss: 0.0612 - val_accuracy: 0.9844\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.98500\n",
      "Epoch 19/100\n",
      "225/225 [==============================] - 5s 24ms/step - loss: 0.1647 - accuracy: 0.9465 - val_loss: 0.0570 - val_accuracy: 0.9825\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.98500\n",
      "Epoch 20/100\n",
      "225/225 [==============================] - 5s 24ms/step - loss: 0.1526 - accuracy: 0.9494 - val_loss: 0.0566 - val_accuracy: 0.9837\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.98500\n",
      "Epoch 21/100\n",
      "225/225 [==============================] - 6s 25ms/step - loss: 0.1521 - accuracy: 0.9540 - val_loss: 0.0562 - val_accuracy: 0.9850\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.98500\n",
      "Epoch 22/100\n",
      "225/225 [==============================] - 7s 33ms/step - loss: 0.1414 - accuracy: 0.9524 - val_loss: 0.0579 - val_accuracy: 0.9819\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.98500\n",
      "Epoch 23/100\n",
      "225/225 [==============================] - 5s 23ms/step - loss: 0.1398 - accuracy: 0.9550 - val_loss: 0.0618 - val_accuracy: 0.9800\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.98500\n",
      "Epoch 24/100\n",
      "225/225 [==============================] - 5s 22ms/step - loss: 0.1367 - accuracy: 0.9549 - val_loss: 0.0571 - val_accuracy: 0.9850\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.98500\n",
      "Epoch 25/100\n",
      "225/225 [==============================] - 5s 22ms/step - loss: 0.1302 - accuracy: 0.9565 - val_loss: 0.0558 - val_accuracy: 0.9844\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.98500\n",
      "Epoch 26/100\n",
      "225/225 [==============================] - 6s 25ms/step - loss: 0.1248 - accuracy: 0.9581 - val_loss: 0.0558 - val_accuracy: 0.9856\n",
      "\n",
      "Epoch 00026: val_accuracy improved from 0.98500 to 0.98563, saving model to H:\\My Drive\\Master\\Machine_Learning\\MachineLearning-2022\\saved_models\\weights-026-0.0558.hdf5\n",
      "Epoch 27/100\n",
      "225/225 [==============================] - 5s 24ms/step - loss: 0.1252 - accuracy: 0.9588 - val_loss: 0.0623 - val_accuracy: 0.9812\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.98563\n",
      "Epoch 28/100\n",
      "225/225 [==============================] - 6s 25ms/step - loss: 0.1260 - accuracy: 0.9618 - val_loss: 0.0551 - val_accuracy: 0.9856\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.98563\n",
      "Epoch 29/100\n",
      "225/225 [==============================] - 5s 24ms/step - loss: 0.1211 - accuracy: 0.9613 - val_loss: 0.0561 - val_accuracy: 0.9819\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.98563\n",
      "Epoch 30/100\n",
      "225/225 [==============================] - 7s 29ms/step - loss: 0.1162 - accuracy: 0.9628 - val_loss: 0.0490 - val_accuracy: 0.9844\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.98563\n",
      "Epoch 31/100\n",
      "225/225 [==============================] - 6s 28ms/step - loss: 0.1167 - accuracy: 0.9609 - val_loss: 0.0529 - val_accuracy: 0.9837\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.98563\n",
      "Epoch 32/100\n",
      "225/225 [==============================] - 5s 24ms/step - loss: 0.1124 - accuracy: 0.9633 - val_loss: 0.0486 - val_accuracy: 0.9856\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.98563\n",
      "Epoch 33/100\n",
      "225/225 [==============================] - 6s 25ms/step - loss: 0.1162 - accuracy: 0.9633 - val_loss: 0.0531 - val_accuracy: 0.9831\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.98563\n",
      "Epoch 34/100\n",
      "225/225 [==============================] - 5s 24ms/step - loss: 0.1112 - accuracy: 0.9649 - val_loss: 0.0497 - val_accuracy: 0.9844\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.98563\n",
      "Epoch 35/100\n",
      "225/225 [==============================] - 5s 24ms/step - loss: 0.1088 - accuracy: 0.9658 - val_loss: 0.0488 - val_accuracy: 0.9856\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.98563\n",
      "Epoch 36/100\n",
      "225/225 [==============================] - 5s 23ms/step - loss: 0.1100 - accuracy: 0.9635 - val_loss: 0.0425 - val_accuracy: 0.9869\n",
      "\n",
      "Epoch 00036: val_accuracy improved from 0.98563 to 0.98687, saving model to H:\\My Drive\\Master\\Machine_Learning\\MachineLearning-2022\\saved_models\\weights-036-0.0425.hdf5\n",
      "Epoch 37/100\n",
      "225/225 [==============================] - 6s 25ms/step - loss: 0.1094 - accuracy: 0.9644 - val_loss: 0.0508 - val_accuracy: 0.9856\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.98687\n",
      "Epoch 38/100\n",
      "225/225 [==============================] - 6s 28ms/step - loss: 0.1013 - accuracy: 0.9673 - val_loss: 0.0556 - val_accuracy: 0.9875\n",
      "\n",
      "Epoch 00038: val_accuracy improved from 0.98687 to 0.98750, saving model to H:\\My Drive\\Master\\Machine_Learning\\MachineLearning-2022\\saved_models\\weights-038-0.0556.hdf5\n",
      "Epoch 39/100\n",
      "225/225 [==============================] - 6s 25ms/step - loss: 0.1042 - accuracy: 0.9665 - val_loss: 0.0434 - val_accuracy: 0.9856\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.98750\n",
      "Epoch 40/100\n",
      "225/225 [==============================] - 6s 25ms/step - loss: 0.1053 - accuracy: 0.9657 - val_loss: 0.0539 - val_accuracy: 0.9856\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.98750\n",
      "Epoch 41/100\n",
      "225/225 [==============================] - 5s 23ms/step - loss: 0.0983 - accuracy: 0.9685 - val_loss: 0.0459 - val_accuracy: 0.9875\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.98750\n",
      "Epoch 42/100\n",
      "225/225 [==============================] - 5s 24ms/step - loss: 0.0947 - accuracy: 0.9688 - val_loss: 0.0602 - val_accuracy: 0.9844\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.98750\n",
      "Epoch 43/100\n",
      "225/225 [==============================] - 5s 24ms/step - loss: 0.0971 - accuracy: 0.9694 - val_loss: 0.0426 - val_accuracy: 0.9881\n",
      "\n",
      "Epoch 00043: val_accuracy improved from 0.98750 to 0.98813, saving model to H:\\My Drive\\Master\\Machine_Learning\\MachineLearning-2022\\saved_models\\weights-043-0.0426.hdf5\n",
      "Epoch 44/100\n",
      "225/225 [==============================] - 6s 24ms/step - loss: 0.0918 - accuracy: 0.9695 - val_loss: 0.0549 - val_accuracy: 0.9862\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.98813\n",
      "Epoch 45/100\n",
      "225/225 [==============================] - 6s 25ms/step - loss: 0.0900 - accuracy: 0.9715 - val_loss: 0.0460 - val_accuracy: 0.9881\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.98813\n",
      "Epoch 46/100\n",
      "225/225 [==============================] - 6s 29ms/step - loss: 0.0858 - accuracy: 0.9726 - val_loss: 0.0449 - val_accuracy: 0.9881\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.98813\n",
      "Epoch 47/100\n",
      "225/225 [==============================] - 7s 32ms/step - loss: 0.0841 - accuracy: 0.9726 - val_loss: 0.0449 - val_accuracy: 0.9869\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.98813\n",
      "Epoch 48/100\n",
      "225/225 [==============================] - 7s 29ms/step - loss: 0.0838 - accuracy: 0.9743 - val_loss: 0.0448 - val_accuracy: 0.9869\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.98813\n",
      "Epoch 49/100\n",
      "225/225 [==============================] - 7s 31ms/step - loss: 0.0865 - accuracy: 0.9715 - val_loss: 0.0483 - val_accuracy: 0.9850\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.98813\n",
      "Epoch 50/100\n",
      "225/225 [==============================] - 7s 32ms/step - loss: 0.0800 - accuracy: 0.9741 - val_loss: 0.0494 - val_accuracy: 0.9862\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.98813\n",
      "Epoch 51/100\n",
      "225/225 [==============================] - 7s 30ms/step - loss: 0.0899 - accuracy: 0.9697 - val_loss: 0.0577 - val_accuracy: 0.9844\n",
      "\n",
      "Epoch 00051: val_accuracy did not improve from 0.98813\n",
      "Epoch 52/100\n",
      "225/225 [==============================] - 5s 24ms/step - loss: 0.0887 - accuracy: 0.9724 - val_loss: 0.0460 - val_accuracy: 0.9894\n",
      "\n",
      "Epoch 00052: val_accuracy improved from 0.98813 to 0.98937, saving model to H:\\My Drive\\Master\\Machine_Learning\\MachineLearning-2022\\saved_models\\weights-052-0.0460.hdf5\n",
      "Epoch 53/100\n",
      "225/225 [==============================] - 5s 24ms/step - loss: 0.0848 - accuracy: 0.9731 - val_loss: 0.0553 - val_accuracy: 0.9869\n",
      "\n",
      "Epoch 00053: val_accuracy did not improve from 0.98937\n",
      "Epoch 54/100\n",
      "225/225 [==============================] - 6s 26ms/step - loss: 0.0798 - accuracy: 0.9723 - val_loss: 0.0506 - val_accuracy: 0.9862\n",
      "\n",
      "Epoch 00054: val_accuracy did not improve from 0.98937\n",
      "Epoch 55/100\n",
      "225/225 [==============================] - 5s 24ms/step - loss: 0.0747 - accuracy: 0.9756 - val_loss: 0.0497 - val_accuracy: 0.9875\n",
      "\n",
      "Epoch 00055: val_accuracy did not improve from 0.98937\n",
      "Epoch 56/100\n",
      "225/225 [==============================] - 5s 23ms/step - loss: 0.0770 - accuracy: 0.9741 - val_loss: 0.0549 - val_accuracy: 0.9862\n",
      "\n",
      "Epoch 00056: val_accuracy did not improve from 0.98937\n",
      "Epoch 57/100\n",
      "225/225 [==============================] - 5s 24ms/step - loss: 0.0808 - accuracy: 0.9736 - val_loss: 0.0473 - val_accuracy: 0.9875\n",
      "\n",
      "Epoch 00057: val_accuracy did not improve from 0.98937\n",
      "Epoch 58/100\n",
      "225/225 [==============================] - 5s 23ms/step - loss: 0.0684 - accuracy: 0.9781 - val_loss: 0.0503 - val_accuracy: 0.9869\n",
      "\n",
      "Epoch 00058: val_accuracy did not improve from 0.98937\n",
      "Epoch 59/100\n",
      "225/225 [==============================] - 5s 21ms/step - loss: 0.0743 - accuracy: 0.9742 - val_loss: 0.0428 - val_accuracy: 0.9875\n",
      "\n",
      "Epoch 00059: val_accuracy did not improve from 0.98937\n",
      "Epoch 60/100\n",
      "225/225 [==============================] - 5s 23ms/step - loss: 0.0776 - accuracy: 0.9742 - val_loss: 0.0539 - val_accuracy: 0.9856\n",
      "\n",
      "Epoch 00060: val_accuracy did not improve from 0.98937\n",
      "Epoch 61/100\n",
      "225/225 [==============================] - 5s 23ms/step - loss: 0.0714 - accuracy: 0.9776 - val_loss: 0.0485 - val_accuracy: 0.9862\n",
      "\n",
      "Epoch 00061: val_accuracy did not improve from 0.98937\n",
      "Epoch 62/100\n",
      "225/225 [==============================] - 7s 31ms/step - loss: 0.0683 - accuracy: 0.9756 - val_loss: 0.0434 - val_accuracy: 0.9887\n",
      "\n",
      "Epoch 00062: val_accuracy did not improve from 0.98937\n",
      "Epoch 63/100\n",
      "225/225 [==============================] - 7s 32ms/step - loss: 0.0722 - accuracy: 0.9767 - val_loss: 0.0519 - val_accuracy: 0.9856\n",
      "\n",
      "Epoch 00063: val_accuracy did not improve from 0.98937\n",
      "Epoch 64/100\n",
      "225/225 [==============================] - 7s 30ms/step - loss: 0.0620 - accuracy: 0.9794 - val_loss: 0.0550 - val_accuracy: 0.9875\n",
      "\n",
      "Epoch 00064: val_accuracy did not improve from 0.98937\n",
      "Epoch 65/100\n",
      "225/225 [==============================] - 6s 25ms/step - loss: 0.0712 - accuracy: 0.9778 - val_loss: 0.0477 - val_accuracy: 0.9869\n",
      "\n",
      "Epoch 00065: val_accuracy did not improve from 0.98937\n",
      "Epoch 66/100\n",
      "225/225 [==============================] - 5s 23ms/step - loss: 0.0660 - accuracy: 0.9783 - val_loss: 0.0483 - val_accuracy: 0.9869\n",
      "\n",
      "Epoch 00066: val_accuracy did not improve from 0.98937\n",
      "Epoch 67/100\n",
      "225/225 [==============================] - 5s 24ms/step - loss: 0.0732 - accuracy: 0.9772 - val_loss: 0.0431 - val_accuracy: 0.9862\n",
      "\n",
      "Epoch 00067: val_accuracy did not improve from 0.98937\n",
      "Epoch 68/100\n",
      "225/225 [==============================] - 5s 23ms/step - loss: 0.0657 - accuracy: 0.9783 - val_loss: 0.0475 - val_accuracy: 0.9856\n",
      "\n",
      "Epoch 00068: val_accuracy did not improve from 0.98937\n",
      "Epoch 69/100\n",
      "225/225 [==============================] - 5s 23ms/step - loss: 0.0691 - accuracy: 0.9769 - val_loss: 0.0476 - val_accuracy: 0.9862\n",
      "\n",
      "Epoch 00069: val_accuracy did not improve from 0.98937\n",
      "Epoch 70/100\n",
      "225/225 [==============================] - 6s 25ms/step - loss: 0.0617 - accuracy: 0.9785 - val_loss: 0.0576 - val_accuracy: 0.9844\n",
      "\n",
      "Epoch 00070: val_accuracy did not improve from 0.98937\n",
      "Epoch 71/100\n",
      "225/225 [==============================] - 5s 21ms/step - loss: 0.0615 - accuracy: 0.9803 - val_loss: 0.0521 - val_accuracy: 0.9881\n",
      "\n",
      "Epoch 00071: val_accuracy did not improve from 0.98937\n",
      "Epoch 72/100\n",
      "225/225 [==============================] - 5s 22ms/step - loss: 0.0649 - accuracy: 0.9785 - val_loss: 0.0459 - val_accuracy: 0.9862\n",
      "\n",
      "Epoch 00072: val_accuracy did not improve from 0.98937\n",
      "Epoch 73/100\n",
      "225/225 [==============================] - 5s 22ms/step - loss: 0.0593 - accuracy: 0.9807 - val_loss: 0.0539 - val_accuracy: 0.9825\n",
      "\n",
      "Epoch 00073: val_accuracy did not improve from 0.98937\n",
      "Epoch 74/100\n",
      "225/225 [==============================] - 5s 23ms/step - loss: 0.0665 - accuracy: 0.9798 - val_loss: 0.0511 - val_accuracy: 0.9856\n",
      "\n",
      "Epoch 00074: val_accuracy did not improve from 0.98937\n",
      "Epoch 75/100\n",
      "225/225 [==============================] - 5s 21ms/step - loss: 0.0631 - accuracy: 0.9782 - val_loss: 0.0513 - val_accuracy: 0.9856\n",
      "\n",
      "Epoch 00075: val_accuracy did not improve from 0.98937\n",
      "Epoch 76/100\n",
      "225/225 [==============================] - 5s 22ms/step - loss: 0.0628 - accuracy: 0.9799 - val_loss: 0.0458 - val_accuracy: 0.9881\n",
      "\n",
      "Epoch 00076: val_accuracy did not improve from 0.98937\n",
      "Epoch 77/100\n",
      "225/225 [==============================] - 5s 22ms/step - loss: 0.0580 - accuracy: 0.9792 - val_loss: 0.0492 - val_accuracy: 0.9856\n",
      "\n",
      "Epoch 00077: val_accuracy did not improve from 0.98937\n",
      "Epoch 78/100\n",
      "225/225 [==============================] - 5s 23ms/step - loss: 0.0572 - accuracy: 0.9810 - val_loss: 0.0569 - val_accuracy: 0.9862\n",
      "\n",
      "Epoch 00078: val_accuracy did not improve from 0.98937\n",
      "Epoch 79/100\n",
      "225/225 [==============================] - 6s 27ms/step - loss: 0.0585 - accuracy: 0.9814 - val_loss: 0.0453 - val_accuracy: 0.9894\n",
      "\n",
      "Epoch 00079: val_accuracy did not improve from 0.98937\n",
      "Epoch 80/100\n",
      "225/225 [==============================] - 6s 27ms/step - loss: 0.0550 - accuracy: 0.9833 - val_loss: 0.0540 - val_accuracy: 0.9875\n",
      "\n",
      "Epoch 00080: val_accuracy did not improve from 0.98937\n",
      "Epoch 81/100\n",
      "225/225 [==============================] - 6s 27ms/step - loss: 0.0542 - accuracy: 0.9816 - val_loss: 0.0509 - val_accuracy: 0.9869\n",
      "\n",
      "Epoch 00081: val_accuracy did not improve from 0.98937\n",
      "Epoch 82/100\n",
      "225/225 [==============================] - 6s 28ms/step - loss: 0.0569 - accuracy: 0.9819 - val_loss: 0.0427 - val_accuracy: 0.9900\n",
      "\n",
      "Epoch 00082: val_accuracy improved from 0.98937 to 0.99000, saving model to H:\\My Drive\\Master\\Machine_Learning\\MachineLearning-2022\\saved_models\\weights-082-0.0427.hdf5\n",
      "Epoch 83/100\n",
      "225/225 [==============================] - 6s 28ms/step - loss: 0.0564 - accuracy: 0.9816 - val_loss: 0.0553 - val_accuracy: 0.9837\n",
      "\n",
      "Epoch 00083: val_accuracy did not improve from 0.99000\n",
      "Epoch 84/100\n",
      "225/225 [==============================] - 6s 29ms/step - loss: 0.0546 - accuracy: 0.9817 - val_loss: 0.0464 - val_accuracy: 0.9887\n",
      "\n",
      "Epoch 00084: val_accuracy did not improve from 0.99000\n",
      "Epoch 85/100\n",
      "225/225 [==============================] - 6s 27ms/step - loss: 0.0525 - accuracy: 0.9826 - val_loss: 0.0530 - val_accuracy: 0.9850\n",
      "\n",
      "Epoch 00085: val_accuracy did not improve from 0.99000\n",
      "Epoch 86/100\n",
      "225/225 [==============================] - 6s 28ms/step - loss: 0.0513 - accuracy: 0.9833 - val_loss: 0.0495 - val_accuracy: 0.9881\n",
      "\n",
      "Epoch 00086: val_accuracy did not improve from 0.99000\n",
      "Epoch 87/100\n",
      "225/225 [==============================] - 5s 21ms/step - loss: 0.0581 - accuracy: 0.9832 - val_loss: 0.0442 - val_accuracy: 0.9887\n",
      "\n",
      "Epoch 00087: val_accuracy did not improve from 0.99000\n",
      "Epoch 88/100\n",
      "225/225 [==============================] - 7s 30ms/step - loss: 0.0508 - accuracy: 0.9840 - val_loss: 0.0437 - val_accuracy: 0.9906\n",
      "\n",
      "Epoch 00088: val_accuracy improved from 0.99000 to 0.99063, saving model to H:\\My Drive\\Master\\Machine_Learning\\MachineLearning-2022\\saved_models\\weights-088-0.0437.hdf5\n",
      "Epoch 89/100\n",
      "225/225 [==============================] - 6s 27ms/step - loss: 0.0494 - accuracy: 0.9837 - val_loss: 0.0479 - val_accuracy: 0.9875\n",
      "\n",
      "Epoch 00089: val_accuracy did not improve from 0.99063\n",
      "Epoch 90/100\n",
      "225/225 [==============================] - 6s 28ms/step - loss: 0.0550 - accuracy: 0.9813 - val_loss: 0.0579 - val_accuracy: 0.9894\n",
      "\n",
      "Epoch 00090: val_accuracy did not improve from 0.99063\n",
      "Epoch 91/100\n",
      "225/225 [==============================] - 5s 22ms/step - loss: 0.0513 - accuracy: 0.9839 - val_loss: 0.0500 - val_accuracy: 0.9900\n",
      "\n",
      "Epoch 00091: val_accuracy did not improve from 0.99063\n",
      "Epoch 92/100\n",
      "225/225 [==============================] - 5s 22ms/step - loss: 0.0485 - accuracy: 0.9834 - val_loss: 0.0542 - val_accuracy: 0.9869\n",
      "\n",
      "Epoch 00092: val_accuracy did not improve from 0.99063\n",
      "Epoch 93/100\n",
      "225/225 [==============================] - 5s 22ms/step - loss: 0.0494 - accuracy: 0.9835 - val_loss: 0.0516 - val_accuracy: 0.9856\n",
      "\n",
      "Epoch 00093: val_accuracy did not improve from 0.99063\n",
      "Epoch 94/100\n",
      "225/225 [==============================] - 5s 21ms/step - loss: 0.0511 - accuracy: 0.9834 - val_loss: 0.0454 - val_accuracy: 0.9881\n",
      "\n",
      "Epoch 00094: val_accuracy did not improve from 0.99063\n",
      "Epoch 95/100\n",
      "225/225 [==============================] - 5s 21ms/step - loss: 0.0489 - accuracy: 0.9837 - val_loss: 0.0481 - val_accuracy: 0.9869\n",
      "\n",
      "Epoch 00095: val_accuracy did not improve from 0.99063\n",
      "Epoch 96/100\n",
      "225/225 [==============================] - 5s 24ms/step - loss: 0.0516 - accuracy: 0.9834 - val_loss: 0.0422 - val_accuracy: 0.9875\n",
      "\n",
      "Epoch 00096: val_accuracy did not improve from 0.99063\n",
      "Epoch 97/100\n",
      "225/225 [==============================] - 6s 26ms/step - loss: 0.0482 - accuracy: 0.9838 - val_loss: 0.0428 - val_accuracy: 0.9875\n",
      "\n",
      "Epoch 00097: val_accuracy did not improve from 0.99063\n",
      "Epoch 98/100\n",
      "225/225 [==============================] - 6s 28ms/step - loss: 0.0502 - accuracy: 0.9832 - val_loss: 0.0498 - val_accuracy: 0.9875\n",
      "\n",
      "Epoch 00098: val_accuracy did not improve from 0.99063\n",
      "Epoch 99/100\n",
      "225/225 [==============================] - 6s 28ms/step - loss: 0.0519 - accuracy: 0.9840 - val_loss: 0.0494 - val_accuracy: 0.9869\n",
      "\n",
      "Epoch 00099: val_accuracy did not improve from 0.99063\n",
      "Epoch 100/100\n",
      "225/225 [==============================] - 6s 28ms/step - loss: 0.0458 - accuracy: 0.9862 - val_loss: 0.0538 - val_accuracy: 0.9869\n",
      "\n",
      "Epoch 00100: val_accuracy did not improve from 0.99063\n"
     ]
    }
   ],
   "source": [
    "model = create_model_2(X_train.shape[1:], y_train_t.shape[-1], top_params[0][0], top_params[0][1], top_params[0][2])\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(lr_schedule),\n",
    "    loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "    metrics=['accuracy'])\n",
    "history = model.fit(X_train, y_train_t, epochs=100, batch_size=64,\n",
    "                    validation_split=0.1, callbacks=final_callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e661bcb2-48f7-4c4e-b591-debde408d0b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
